{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khushbupatel333/Bike_Sharing_Prediction/blob/main/Bike_Sharing_prediction_Regression_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    \n",
        "Bike Sharing Demand Prediction"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Khushbupatel333/Bike_Sharing_Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nowadays Rental bikes are introduced in many urban cities for the improvement of mobile comfort.Itbis important to make rental bikes avaialbel to the public at the right time as it makes watate of time.Eventyally providing a city with supply of rental bikes become a major concern.\n",
        "\n",
        "The main objective is to predict the bike count required at each hour for supply of rental bikes.\n",
        "\n",
        "The dataset contains information (Temperature,Humidity, Windspeed, dewpoint, visibility, solar radiation, snowfall, rainfall) the number of bike rented per hour."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from datetime import datetime\n",
        "import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.metrics import accuracy_score,mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import XGBRFClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import math"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "#bike_df= pd.read_csv('/Drive/MyDrive/ColabNotebook/BikeData.csv',encoding='latin')\n",
        "#bike=pd.read_csv('content/google.com/drive/MyDrive/ColabNotebook/BikeData.csv',encoding='latin')\n",
        "\n",
        "\n",
        "data = {'Date':['03-11-2022','12-02-2001','09-09-2004','12-03-2012','10-10-2019','12-04-2016','14-02-2004','23-06-2013','08-11-2016','09-11-2012','03-11-2022','12-02-2001','09-09-2004','12-03-2012','10-10-2019','12-04-2016','14-02-2004','23-06-2013','08-11-2016','09-11-2012','03-11-2022','12-02-2001','09-09-2004','12-03-2012','10-10-2019','12-04-2016','14-02-2004','23-06-2013','08-11-2016','09-11-2012','08-07-2000','12-03-2021','21-03-2012','09-12-2021','03-11-2022','12-02-2001','09-09-2004','12-03-2012','10-10-2019','12-04-2016','14-02-2004','23-06-2013','08-11-2016','09-11-2012','03-11-2022','12-02-2001','09-09-2004','12-03-2012','10-10-2019','12-04-2016','14-02-2004','23-06-2013','08-11-2016','09-11-2012','03-11-2022','12-02-2001','09-09-2004','12-03-2012','10-10-2019','12-07-2002','12-03-2022','21-11-2022','09-06-2001','06-12-2021','04-12-2020','12-01-2021','22-03-2001','09-03-2000','04-12-2012','12-02-2021','12-07-2000','12-03-2000','15-04-2000','21-09-2000','21-06-2022','23-06-2011','23-12-2000','22-10-2000','11-01-2000','09-05-2023','12-07-2021','22-12-2000','09-05-2022','12-12-2000','12-04-2021','22-12-2003','23-01-2002','22-06-2023','21-02-2009','20-12-2000'],\n",
        "        'Rented_bike_count':[120,45,200,340,134,300,376,500,537,346,120,45,200,340,134,300,376,500,537,346,120,45,200,340,134,300,376,500,537,346,120,45,200,340,134,300,376,500,537,346,120,45,200,340,134,300,376,500,537,346,120,45,200,340,134,300,376,500,537,346,120,45,200,340,134,300,376,500,537,346,120,45,200,340,134,300,376,500,137,346,123,124,432,442,432,440,123,123,260,120],\n",
        "        'Hour':[1,6,3,5,3,4,5,0,4,10,1,6,3,5,3,4,5,0,4,10,1,6,3,5,3,4,5,0,4,10,1,6,3,5,3,4,5,0,4,10,1,6,3,5,3,4,5,0,4,10,1,6,3,5,3,4,5,0,4,10,1,6,3,5,3,4,5,0,4,10,1,6,3,5,3,4,5,0,4,10,1,0,4,3,4,7,10,3,4,4],\n",
        "        'Temperature(°C)':[-6.4,-4.5,-2.3,-4.4,-6.7,-8.4,-5.9,-7.0,-8.9,-9.0,-6.4,-4.5,-2.3,-4.4,-6.7,-8.4,-5.9,-7.0,-8.9,-9.0,-6.4,-4.5,-2.3,-4.4,-6.7,-8.4,-5.9,-7.0,-8.9,-9.0,-6.4,-4.5,-2.3,-4.4,-6.7,-8.4,-5.9,-7.0,-8.9,-9.0,-6.4,-4.5,-2.3,-4.4,-2.7,-4.4,-5.9,-2.0,-1.9,-9.0,-6.4,-4.5,-2.3,-4.4,-6.7,-1.4,-5.9,-2.0,-6.9,-3.0,-3.4,-4.5,-2.3,-4.4,-2.7,-2.4,-2.9,-2.0,-7.9,-2.0,-4.4,-4.5,-3.3,-1.4,-6.7,-2.4,-5.9,-2.0,-3.9,-2.0,-2.0,-1.2,-0.0,-2.0,-1.3,-0.8,-1.3,-0.8,-3.9,-1.2],\n",
        "        'Humidity(%)':[36,24,15,45,33,56,40,38,41,38,36,24,15,45,33,56,40,38,41,38,36,24,15,45,33,56,40,38,41,38,36,24,15,45,33,56,40,38,41,38,36,24,15,45,33,56,40,38,41,38,36,24,15,45,33,56,40,38,41,38,36,24,15,45,33,56,40,38,41,38,36,24,15,45,33,56,40,38,41,38,20,33,24,45,28,23,22,24,56,10],\n",
        "        'Wind_speed(m/s)':[0.9,1.2,1.6,2.3,4.0,4.3,0.5,1.4,2.6,2.1,0.9,1.2,1.6,2.3,4.0,4.3,0.5,1.4,2.6,2.1,0.9,1.2,1.6,2.3,4.0,4.3,0.5,1.4,2.6,2.1,0.9,1.2,1.6,2.3,4.0,4.3,0.5,1.4,2.6,2.1,0.9,1.2,1.6,2.3,4.0,4.3,0.5,1.4,2.6,2.1,0.9,1.2,1.6,2.3,4.0,4.3,0.5,1.4,2.6,2.1,0.9,1.2,1.6,2.3,4.0,4.3,0.5,1.4,2.6,2.1,0.9,1.2,1.6,2.3,4.0,4.3,0.5,1.4,2.6,2.1,2.8,4.6,3.2,0.9,3.5,1.2,1.3,4.2,1.3,1.5],\n",
        "        'Visiblity(10cm)':[1000,1000,1500,1400,1000,2000,1300,2100,2000,1300,1000,1000,1500,1400,1000,2000,1300,2100,2000,1300,1000,1000,1500,1400,1000,2000,1300,2100,2000,1300,1000,1000,1500,1400,1000,2000,1300,2100,2000,1300,1000,1000,1500,1400,1000,2000,1300,2100,2000,1300,1000,1000,1500,1400,1000,2000,1300,2100,2000,1300,1000,1000,1500,1400,1000,2000,1300,2100,2000,1300,1000,1000,1500,1400,1000,2000,1300,2100,2000,1300,1000,1200,1300,1200,1500,1450,1200,1000,1200,1000],\n",
        "        'Dew_point':[-42.2,-31.2,-12.6,-33.2,-41.2,-11.5,-6.23,-24.5,-52.3,-31.2,-42.2,-31.2,-12.6,-33.2,-41.2,-11.5,-6.23,-24.5,-52.3,-31.2,-42.2,-31.2,-12.6,-33.2,-41.2,-11.5,-6.23,-24.5,-52.3,-31.2,-42.2,-31.2,-12.6,-33.2,-41.2,-11.5,-6.23,-24.5,-52.3,-31.2,-42.2,-31.2,-12.6,-33.2,-41.2,-11.5,-6.23,-24.5,-52.3,-31.2,-42.2,-31.2,-12.6,-33.2,-41.2,-11.5,-6.23,-24.5,-52.3,-31.2,-42.2,-31.2,-12.6,-33.2,-41.2,-11.5,-6.23,-24.5,-52.3,-31.2,-42.2,-31.2,-12.6,-33.2,-41.2,-11.5,-6.23,-24.5,-52.3,-31.2,-12.3,-1.4,-6.5,-2.5,-12.0,-1.8,-6.7,-4.3,6.4,4.5],\n",
        "        'Solar_rediation(MJ/m2)':[737.3,738,526,526.3,637.3,52.2,637.2,314,626.9,975,638.4,621.9,11.5,652.5,123.7,315.8,425.3,526.6,326.3,637,120,45,200,340,134,300,376,500,537,346,120,45,200,340,134,300,376,500,537,346,737.3,738,526,526.3,637.3,52.2,637.2,314,626.9,975,638.4,621.9,11.5,652.5,123.7,315.8,425.3,526.6,326.3,637,120,45,200,340,134,300,376,500,537,346,120,45,200,340,134,300,376,500,537,346,123,456,234,123,134,234,145,345,234,123],\n",
        "        'Rainfall(mm)':[333.0,638.4,621.9,11.5,652.5,123.7,315.8,425.3,526.6,326.3,637,638.4,621.9,11.5,652.5,123.7,315.8,425.3,526.6,326.3,637,638.4,621.9,11.5,652.5,123.7,315.8,425.3,526.6,326.3,637,638.4,621.9,11.5,652.5,123.7,315.8,425.3,526.6,326.3,637,638.4,621.9,11.5,652.5,123.7,315.8,425.3,526.6,326.3,637,638.4,621.9,11.5,652.5,123.7,315.8,425.3,526.6,326.3,637,638.4,621.9,11.5,652.5,123.7,315.8,425.3,526.6,326.3,637,638.4,621.9,11.5,652.5,123.7,315.8,425.3,526.6,326.3,134.6,134.7,234.7,425.4,234.6,234.7,125.7,234.7,345.7,455.7],\n",
        "        'Snowfall(cm)':[0.2,2.9,3.0,3.2,6.0,2.3,8.5,4.6,6.5,12.6,0.2,2.9,3.0,3.2,6.0,2.3,8.5,4.6,6.5,12.6,0.2,2.9,3.0,3.2,6.0,2.3,8.5,4.6,6.5,12.6,0.2,2.9,3.0,3.2,6.0,2.3,8.5,4.6,6.5,12.6,0.2,2.9,3.0,3.2,6.0,2.3,8.5,4.6,6.5,12.6,0.2,2.9,3.0,3.2,6.0,2.3,8.5,4.6,6.5,12.6,0.2,2.9,3.0,3.2,6.0,2.3,8.5,4.6,6.5,12.6,0.2,2.9,3.0,3.2,6.0,2.3,8.5,4.6,6.5,12.6,1.2,4.6,4.7,2.3,4.7,2.5,10.7,4.7,3.6,7.8],\n",
        "        'Season':['Winter','Winter','Winter','Winter','Winter','Summer','Summer','Summer','Winter','Winter','Monsoon','Winter','Monsoon','Winter','Monsoon','Summer','Summer','Summer','Winter','Winter','Winter','Winter','Winter','Winter','Winter','Summer','Summer','Summer','Winter','Winter','Monsoon','Winter','Monsoon','Winter','Monsoon','Summer','Summer','Summer','Winter','Winter','Winter','Winter','Winter','Winter','Winter','Summer','Summer','Summer','Winter','Winter','Monsoon','Winter','Monsoon','Winter','Monsoon','Summer','Summer','Summer','Winter','Winter','Winter','Winter','Winter','Winter','Winter','Summer','Summer','Summer','Winter','Winter','Monsoon','Winter','Monsoon','Winter','Monsoon','Summer','Summer','Summer','Winter','Winter','Summer','Summer','Summer','Summer','Summer','Summer','Summer','Summer','Summer','Summer'],\n",
        "        'Holiday':['No','No','No','No','Yes','No','No','No','No','Yes','Yes','Yes','No','Yes','No','Yes','No','Yes','Yes','Yes','Yes','No','Yes','No','Yes','No','Yes','No','Yes','Yes','No','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','No','No','No','No','Yes','No','No','No','No','Yes','Yes','Yes','No','Yes','No','Yes','No','Yes','Yes','Yes','Yes','No','Yes','No','Yes','No','Yes','No','Yes','Yes','No','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes'],\n",
        "        'Functioning_day':['Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','No','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes','Yes']\n",
        "\n",
        "        }\n",
        "\n",
        "dataset=pd.DataFrame(data)\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "len(dataset[dataset.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "print(dataset.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset is Mobiticket booking dataset .This challenge asks you to build a model that predicts the number of seats that Mobiticket can expect to sell for each ride i.e for a specific rate on a specific date and time.\n",
        "\n",
        "There are 14 routes in this dataset.All of the routes end in Nairobi and origionate in towns to the North West of Nairobi towords Lake Victoria.\n",
        "\n",
        "This dataset has 10 rows and 12 columns and has some null and missing values."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "dataset.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date : Date of the day\n",
        "\n",
        "Rented_bike_count : Number of rented bike per hour\n",
        "\n",
        "Hour : The hour of the day\n",
        "\n",
        "Temperature (°C) : Temperature in celcius\n",
        "\n",
        "Humidity (%) : Humidity in the air\n",
        "\n",
        "Wind_speed(m/s) : speed of the wind m/s\n",
        "\n",
        "Visiblity (10cm) : visiblity in m,type\n",
        "\n",
        "Dew_point(°C) : Temprature of beginning of day\n",
        "\n",
        "Solar_radiation(MJ/m2) : sun contribution\n",
        "\n",
        "Rainfall(mm) : Amount of raining  in cm\n",
        "\n",
        "Snowfall (cm) : Amount of snowing in cm\n",
        "\n",
        "Season : Season of the year\n",
        "\n",
        "Holiday : If the day is holiday or not\n",
        "\n",
        "Functioning_day : If the day is functioning or not"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "for i in dataset.columns.tolist():\n",
        " print('Number of unique values:',dataset[i].nunique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Create copy of data to new data\n",
        "\n",
        "df=dataset.copy()\n",
        "\n",
        "#Print all the unique values from dataset\n",
        "print(df.nunique())\n",
        "\n",
        "#Removing Duplicate values\n",
        "duplicate=len(df[df.duplicated()])\n",
        "print(\"Number of duplicate values:\",duplicate)\n",
        "\n",
        "\n",
        "#Count missing values in each column\n",
        "print(df.isnull().sum())\n",
        "#print(df)\n",
        "\n",
        "#All columns in the data have names with symbols so we rename the names of columns\n",
        "df=df.rename(columns={'Temperature(°C)':'Temperature','Humidity(%)':'Humidity','Wind_speed(m/s)':'Windspeed','Visiblity(10cm)':'Visiblity','Dew_point(°C)':'Dew_point','Solar_rediation(MJ/m2)':'Solar_rediation','Rainfall(mm)':'Rainfall','Snowfall(cm)':'Snowfall'})\n",
        "#print(df)\n",
        "\n",
        "\n",
        "#Breaking the date column\n",
        "#Splitting date column because this is in string format as year,month ,day.\n",
        "\n",
        "#Changing the date column into categories\n",
        "\n",
        "df['Date']=df['Date'].apply(lambda x:dt.datetime.strptime(x,\"%d-%m-%Y\"))\n",
        "df['year']=df['Date'].dt.year\n",
        "df['month']=df['Date'].dt.month\n",
        "df['day']=df['Date'].dt.day_name()\n",
        "df['month']=df['Date'].dt.month_name()\n",
        "print(df)\n",
        "\n",
        "#Create new column called Weekends\n",
        "\n",
        "df['Weekends']=df['day'].apply(lambda x:1 if x=='Saturday' or x=='Sunday' else 0)\n",
        "df=df.drop(columns=['Date','day','year'],axis=1)\n",
        "#df['Weekends']=df['Date'].dt.Weekends_name()\n",
        "\n",
        "df.head()\n",
        "df['month']"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- I have done some updation and changes in my data using some  built in function and methods.\n",
        "\n",
        "- First of all I copied my data in another variable called df.\n",
        "\n",
        "- Then I used unique() method to fetch unique value from data.So I used unique method on seat_number column to get unique country.So I got list of seat number from data.\n",
        "\n",
        "- After this I used nunique() method to get count of unique values.\n",
        "\n",
        "- Then I checked duplicate values using duplicated method on data.So I got data without duplicate values.\n",
        "\n",
        "- Next step was to find null and missing values and handling them.So using isnull() method I checked my data but there is no missing value.\n",
        "\n",
        "- Then I evaluate null value using method isnull().So I got null or missing values in data.\n",
        "\n",
        "- Then I rename all the features name with new names for easy task.\n",
        "\n",
        "- Then next there is one column date which is in date format so I break date column in year,month and day parts .Then for more created another new feature weekends for the column day.\n",
        "\n",
        "- Then after all this I dropped year,date and day columns to clear the data.\n",
        "\n",
        "- Finally I got well sorted and maintain data with proper format."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We are going to analyse the relation of feature with our dependent variable.Our dependent variable is Rented bike count.***\n",
        "\n",
        "***So we analyse this columns by using some visualisation plots***"
      ],
      "metadata": {
        "id": "9_B4G866-VRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Analysis of Categorical data ***\n",
        "\n",
        "1. Month\n",
        "2. Weekends\n",
        "3. Hour\n",
        "4. Functioning_day\n",
        "5. Season\n",
        "6. Holiday"
      ],
      "metadata": {
        "id": "2i6JGTlc837_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart 1 Bar plots for Categorical data"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "\n",
        "\n",
        "#Getting Categorical data\n",
        "cat_col=['Hour','month','Season','Holiday','Functioning_day']\n",
        "\n",
        "\n",
        "#Bar plots for Categorical features and Rented bike count\n",
        "plt.figure(figsize=(15,10))\n",
        "for n,col in enumerate(cat_col):\n",
        " plt.subplot(2,3,n+1)\n",
        " plt.title(col)\n",
        " sns.barplot(data=df,x=col,y='Rented_bike_count');\n",
        " plt.tight_layout();"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plots are a type of data visualization used to represent the dat in the form of rectangular bars.The heights of bars represent the value of data points and the width of each bar represent the category of data.\n",
        "\n",
        " So, I used line charts to represent my Dataset."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above chart we notice the different level of each feature.There are total of holiday,seasons ,month,functioning_day."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 Target variable with Functioning day"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.countplot(x=df['Rented_bike_count'],hue=df['Functioning_day'])\n",
        "plt.title('Is functioning day affect Rented bike count')\n",
        "plt.legend(['high','low'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The countplot is used to represent the occurrence of the observation present in the categorical variables.It uses the concept of bar charts for visual depiction.\n",
        "\n",
        "So I used this plot to represent my data"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see I have used two features Target variable and functioning_day.There you will notice that functioning day is not affecting rented bike count more."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 Visualising  Hour column"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "#Visualizing count plot for Hour\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "for n,col in enumerate(['Season','Holiday','Functioning_day','month']):\n",
        " plt.subplot(2,2,n+1)\n",
        " plt.title(col)\n",
        " sns.pointplot(data=df,x='Hour',y='Rented_bike_count',hue=col)\n",
        " plt.tight_layout();"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Point plot represent the estimate of central tendency for the numeric variable by the position of dot.\n",
        "\n",
        "It also provides some indication of the uncertainty around that estimate using error.So,For large dataset it is good visual method."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see I have used pointplot for all the categorical columns to represent the distribution of data ."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 Point Plot for Month column"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "#Creating Count plot for month\n",
        "\n",
        "plt.figure(figsize=(18,5))\n",
        "for n,col in enumerate(['Season','Holiday','Functioning_day']):\n",
        " plt.subplot(1,4,n+1)\n",
        " plt.title(col)\n",
        " sns.pointplot(data=df,x='month',y='Rented_bike_count',hue=col)\n",
        " plt.tight_layout();"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Point plot represent the estimate of the central tendency of a numeric variable by position of the dot and provide some indiction of the estimate using error bars.\n",
        "\n",
        "So ,I used this graph to represent month col woith another columns."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above graph you can see that how the month features is related or distributed in other features."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 Visualisation of Numerical data againts Rented_bike_count"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting Numerical data and making new column to store\n",
        "\n",
        "Num_col=['Temperature','Humidity','Windspeed','Visiblity','Dew_point','Solar_rediation','Rainfall','Snowfall']\n",
        "print(Num_col)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "DwfT0-FUfYHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.countplot(x=df['Rented_bike_count'],hue=df['Temperature'])\n",
        "plt.title('Is Temperature affect Rented bike count')\n",
        "plt.legend(['No','Yes'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The countplot is used to represent the occurrence of the observation present in the categorical variables.It uses the concept of bar charts for visual depiction.\n",
        "\n",
        "So I used this plot to represent my data"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In above graph I used bar plot on Temperature and Target variablecolumn.This graph will help us to know the count of features."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 Target variable with Holiday variable"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.countplot(x=df['Rented_bike_count'],hue=df['Holiday'])\n",
        "plt.title('Ia Holiday affect the bike cout')\n",
        "plt.legend(['High','low'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "count plots are used to show count of values in Dataset.Using count charts we see which subgroup is hightes or most common and how other groups are compared.\n",
        "\n",
        "   Then ,I used bar plot to represents the target variable and Holiday columns."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above count plot visualisation I notice the affection of Holiday on Rented bike count feature.\n",
        "\n",
        "You you see Holiday affect somewhere to decrease the number of rented bike ."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 histogram for whole dataset"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting histograms for distribution of data\n",
        "\n",
        "fig=plt.figure(figsize=(15,20))\n",
        "ax=fig.gca()\n",
        "df.hist(ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histograms are graphs showing frequency distribution.It represent the number distribution within each given intervals.\n",
        "\n",
        "So to show my data I used histogram to whole data."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Histogram you can check the distribution of each feature in the data.\n",
        "\n",
        "As you can see in above graph there are some features which are important like Hour, Temperature and some are not useful like Weekends ."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart-8 Box plot representation of target variable with visibility"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.boxplot(x=df['Visiblity'],y=df['Rented_bike_count'],data=df)\n",
        "plt.title('Box plot representation')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Box plot is method for graphically depicting group of numerical data through their quartiles.The Box plot extends from the Q1 to Q3 quartile values of data.\n",
        "\n",
        "So,I used this chart to show the distribution."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above box plot graph you can see the distribution of both variable and how the visibility affecting the target variable."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Char-9 Target variable with Season"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.countplot(x=df['Rented_bike_count'],hue=df['Season'])\n",
        "plt.title('How much seasons affect Rented bike count')\n",
        "plt.legend(['Summer','Winter','Monsoon'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "countplot is used to represent the occurrence(counts) of the observation present in the categories.It uses the concept of a bar chart for the visual depiction."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used season feature with rented bike count to show how seasons affects the target variable.\n",
        "\n",
        "You can see that every season winter,summer and monsoon are affecting the Rented bike count.Summer and winter seasons affected most of the time ."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "sns.heatmap(df.corr(),annot=True,fmt='.2f')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heat maps are table showing correlation coefficient between variables.A correlation matrix is used to summarise data as input into more advance analysis.The range of correlation is [1,-1].\n",
        "\n",
        "  Hence,I used Heatmap to show relation between my Variables."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we know correlation heatmap is used to calculate the correlation between all pairs of columns in th dataset.\n",
        "\n",
        "You can see close realtive pair .This is showing lots of numbers to look at ,it display them using colors like red, Black, Orange etc."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "\n",
        "sns.pairplot(df,hue='Season')"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The seaborn pairplot allow us to pairwise relationship between variables within a Dataset.This create a nice visualise and helps us to understand the data by summrizing a large amount of data in a single figure."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "#First create copy of dataset\n",
        "import statistics\n",
        "df=dataset.copy()\n",
        "\n",
        "# Visualising the missing values\n",
        "\n",
        "sns.heatmap(df.isnull())\n",
        "\n",
        "#count missing values\n",
        "df.isnull().sum()\n",
        "#df.head()\n",
        "\n",
        "\n",
        "#Changing the date column into categories\n",
        "\n",
        "df['Date']=df['Date'].apply(lambda x:dt.datetime.strptime(x,\"%d-%m-%Y\"))\n",
        "df['year']=df['Date'].dt.year\n",
        "df['month']=df['Date'].dt.month\n",
        "df['day']=df['Date'].dt.day_name()\n",
        "df['month']=df['Date'].dt.month_name()\n",
        "print(df)\n",
        "\n",
        "#Creating new feature\n",
        "df['Weekends']=df['day'].apply(lambda x:1 if x=='Saturday' or x=='Sunday' else 0)\n",
        "\n",
        "#Droping columns Date ,day and year\n",
        "df=df.drop(columns=['Date','day','year','Dew_point','Humidity(%)'],axis=1)\n",
        "\n",
        "df=df.rename(columns={'Temperature(°C)':'Temperature','Humidity(%)':'Humidity','Wind_speed(m/s)':'Windspeed','Visiblity(10cm)':'Visiblity','Dew_point(°C)':'Dew_point','Solar_rediation(MJ/m2)':'Solar_rediation','Rainfall(mm)':'Rainfall','Snowfall(cm)':'Snowfall'})\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So here my database First I copied my data to new variable called df .After that for detecting and finding missing values in data I used isnull() method.I called isnull() method with database.\n",
        "\n",
        "    \n",
        "After that I I replace all the null values with NaN and then find the mean of the max_capacity column.After finding the mean  I replace NaN with mean values.\n",
        "\n",
        "I also used median method same as mean method for missing values detection.So ,I used this two method for handling missing values.This methods are very easy to implement and accurate and we can import this using python from statistics ."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Multicollinearity reduction"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "#There are many features but I want only important feature which are required for my model\n",
        "df.head()\n",
        "\n",
        "plt.figure(figsize=(16,15))\n",
        "corr=df.corr()\n",
        "sns.heatmap(corr,annot=True,fmt='.2f',annot_kws={'size':15})\n",
        "plt.title('Corration heat map')\n",
        "\n",
        "\n",
        "#Checking multicollinearity\n",
        "#Cheking multicollinearity\n",
        "#defining VIF\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def cal_vif(x):\n",
        " vif=pd.DataFrame()\n",
        " vif['variables']=x.columns\n",
        " vif['VIF']=[variance_inflation_factor(x.values,i) for i in range(x.shape[1])]\n",
        " return vif\n",
        "\n",
        "#Checking variance inflation factors\n",
        "vif_cal=cal_vif(df[[i for i in df.describe().columns if i not in ['Rented_bike_count']]])\n",
        "vif_cal\n",
        "#df.head()\n",
        "#I want some features so I have deleted all not required features already"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Categorical encoding"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the Categorical columns into numerical columns\n",
        "\n",
        "df1=pd.get_dummies(df,columns=['Hour','Season','Holiday','Functioning_day','month','Weekends'])\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "sfbGFZlG8BII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# split the dataset into 70:30 ratio\n",
        "\n",
        "#We do some experiments to normalised variable\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x=df1.drop(['Rented_bike_count'],axis=1)\n",
        "y=df1['Rented_bike_count']\n",
        "\n",
        "x\n",
        "#Splitting data in train and test\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=42)\n",
        "x_columns=x.columns\n",
        "x_columns\n",
        "#x_train.head()\n",
        "#x_test.head()\n",
        "#y_test.head()\n",
        "#x_train.shape\n",
        "#y_test.shape"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have many features in my dataset So ,I used 70:30 ratio for splitting dataset.70% dataset for training dataset and 30% for testing dataset.\n",
        "\n",
        "I choose this ratio because this will help me in further operation ."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Scaling  the features"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforming the features x_train and x_test\n",
        "\n",
        "#Initializing the Min Max Scaler\n",
        "scaler= MinMaxScaler()\n",
        "x_train= scaler.fit_transform(x_train)\n",
        "x_test=scaler.transform(x_test)\n",
        "\n",
        "x_train\n",
        "x_test\n",
        "\n",
        "#Transfrom data\n",
        "x_train=pd.DataFrame(x_train, columns=x_columns)\n",
        "x_test=pd.DataFrame(x_test, columns=x_columns)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Function for metric value"
      ],
      "metadata": {
        "id": "JqdxE2wcuwtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_importance(model):\n",
        " try:\n",
        "   importance=model.feature_importance_\n",
        "   feature=x_columns\n",
        " except:\n",
        "   importance=np.abs(model.coef_)\n",
        "   feature=x_columns\n",
        " indices=np.argsort(importance)\n",
        " indices=indices[20::-1]\n",
        "\n",
        "\n",
        " plt.figure(figsize=(12,4))\n",
        " plt.barh(range(len(indices)),importance[indices])\n",
        " plt.yticks(range(len(indices)),[feature[i] for i in indices])\n",
        " plt.title('Feature Importance')\n",
        " plt.show()"
      ],
      "metadata": {
        "id": "fBj12rg6u4Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "\n",
        "#split the dataset in test and train\n",
        "\n",
        "#x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=0)\n",
        "#print(x_train)\n",
        "#print(x_test)\n",
        "\n",
        "#fitting model to the training Dataset\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg=LinearRegression()\n",
        "reg.fit(x_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "reg_pred=reg.predict(x_test)\n",
        "#x_pred=reg.predict(x_train)\n",
        "#print(reg_pred)\n",
        "\n",
        "reg.score(x_train,y_train)\n",
        "reg.intercept_\n",
        "\n",
        "reg.coef_"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "#evaluation matrices\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import sklearn.metrics\n",
        "import math\n",
        "\n",
        "#Fuction to calculate matric scores\n",
        "\n",
        "def score_metric(actual,predicted):\n",
        " mae=mean_absolute_error(actual**2,predicted**2)\n",
        " print(\"mean absolute error:\",mae)\n",
        " mse=mean_squared_error(actual**2, predicted**2)\n",
        " print(\"mean squared error:\",mse)\n",
        " print(\"Root mean squared error:\",np.sqrt(mse))\n",
        " print(\"R2 score:\",r2_score(actual**2,predicted**2))\n",
        "\n",
        "\n",
        "#Getting score chart\n",
        "score_metric(y_test,reg_pred)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Hyperparameter tunning on Linear Regression"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "#Using GridSearchCV for Hyperparameter tunining\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "#Prameters for Linear regression model\n",
        "\n",
        "linear=LinearRegression ()\n",
        "parameter={'fit_intercept':[True]\n",
        "\n",
        "          }\n",
        "\n",
        "#Using Grid Search Hyperparameter tunining\n",
        "reg_grid_search=GridSearchCV(linear,parameter,cv=5,n_jobs=1)\n",
        "\n",
        "#Fitting model and evaluating the score\n",
        "reg_grid_search.fit(x_train,y_train)\n",
        "\n",
        "print('The best value to be found out:',reg_grid_search.best_params_)\n",
        "\n",
        "#Prediction of GridSearchCV model\n",
        "\n",
        "grid_search_pred=reg_grid_search.predict(x_test)\n",
        "#print(grid_search_pred)\n",
        "\n",
        "score_metric(grid_search_pred,y_test)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance\n",
        "\n",
        "feature_importance(reg)"
      ],
      "metadata": {
        "id": "wN_idQuLybZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting the Random Forest classifier to the training set\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "clf=RandomForestRegressor()\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "#predicting the test set result\n",
        "\n",
        "clf_pred=clf.predict(x_test)\n",
        "#print(clf_pred)\n",
        "\n",
        "clf.score(x_train,y_train)"
      ],
      "metadata": {
        "id": "aQDiyDx_Hilm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "\n",
        "#evaluation matrices\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import sklearn.metrics\n",
        "import math\n",
        "\n",
        "#Using MSE metrics method\n",
        "clf_mse= sklearn.metrics.mean_squared_error(y_test,clf_pred)\n",
        "print(\"MSE\",clf_mse)\n",
        "\n",
        "#Using RMSE metrics method\n",
        "clf_RMSE= math.sqrt(clf_mse)\n",
        "print(\"RMSE\",clf_RMSE)\n",
        "\n",
        "#Using MAE metric method\n",
        "print(\"MAE:\",mean_absolute_error(y_test,clf_pred))\n",
        "\n",
        "#Using R2 Score metrics method\n",
        "print(\"R2 Score:\",r2_score(y_test,clf_pred))\n",
        "\n",
        "score_metric(y_test,clf_pred)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Hyperparameter Tuning on Random Forest"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "#Getting parameter for Hyperparameter tunining\n",
        "\n",
        "param={#'n_estimator':[100,150,200],\n",
        "       'min_samples_leaf':[6,4,2],\n",
        "       'max_depth':[30,20,25],\n",
        "       'min_samples_split':[30,25,20],\n",
        "       'max_features':['auto','sqrt','log2']\n",
        "       }\n",
        "\n",
        "#Using Grid Search\n",
        "forest_grid=GridSearchCV(RandomForestRegressor(),param_grid=param,n_jobs=-1,cv=5)\n",
        "\n",
        "# Fit the Algorithm\n",
        "forest_grid.fit(x_train,y_train)\n",
        "\n",
        "print('The best value to be found out:',forest_grid.best_params_)\n",
        "\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "forest_grid_pred=forest_grid.predict(x_test)\n",
        "\n",
        "#Getting evaluation metric score\n",
        "\n",
        "score_metric(y_test, forest_grid_pred)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lasso Regressor"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting Decision tree classifier to training dataset\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "#Fitting the model\n",
        "L1 = Lasso(alpha=0.01,max_iter=1000)\n",
        "L1.fit(x_train,y_train)\n",
        "\n",
        "L1.score(x_train,y_train)\n",
        "\n",
        "#Predicting the score\n",
        "\n",
        "L1_pred=L1.predict(x_test)\n",
        "\n",
        "L1.coef_\n",
        "\n",
        "L1.intercept_"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "#evaluation matrices\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "import sklearn.metrics\n",
        "import math\n",
        "\n",
        "#Using MSE metrics method\n",
        "dec_mse= sklearn.metrics.mean_squared_error(y_test,L1_pred)\n",
        "print(\"MSE\",dec_mse)\n",
        "\n",
        "#Using RMSE metrics method\n",
        "dec_RMSE= math.sqrt(dec_mse)\n",
        "print(\"RMSE\",dec_RMSE)\n",
        "\n",
        "#Using MAE metric method\n",
        "print(\"MAE:\",mean_absolute_error(y_test,L1_pred))\n",
        "\n",
        "\n",
        "#Using R2 Score metrics method\n",
        "print(\"R2 Score:\",r2_score(y_test,L1_pred))\n",
        "\n",
        "\n",
        "#Using metric score function\n",
        "\n",
        "score_metric(y_test,L1_pred)"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Hyperparameter Tuning on Lasso"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "#Using Grid search for hyperparameter tunning\n",
        "\n",
        "L=Lasso()\n",
        "para={'alpha':[0.001,0.01,0.1,1,10,100]\n",
        "     }\n",
        "\n",
        "lasso=GridSearchCV(L,param_grid=para,cv=5,n_jobs=-1)\n",
        "\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "lasso.fit(x_train,y_train)\n",
        "print('The best value to be found out:',lasso.best_params_)\n",
        "optimal=lasso.best_estimator_\n",
        "# Predict on the model\n",
        "\n",
        "lasso_grid_pred=optimal.predict(x_test)\n",
        "score_metric(y_test, lasso_grid_pred)\n",
        "#r2_score(y_test,lasso_grid_pred)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance\n",
        "\n",
        "feature_importance(L1)"
      ],
      "metadata": {
        "id": "vwIdptbJzIAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hyperparameter tunning on Ridge"
      ],
      "metadata": {
        "id": "gm7WJLxCZFZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ridge With Hyperparameter tunning\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Using GridSearchCV for Ridge\n",
        "ridge=Ridge()\n",
        "param={'alpha':[1e-15,1e-10,1e-5,1e-3,1e-1,1,3,5,8,10,20]\n",
        "\n",
        "      }\n",
        "\n",
        "L2=GridSearchCV(ridge,param,cv=5,n_jobs=-1)\n",
        "\n",
        "#Fitting the algorithm\n",
        "\n",
        "L2.fit(x_train,y_train)\n",
        "print('The best value to be found out:',L2.best_params_)\n",
        "\n",
        "model=L2.best_estimator_\n",
        "#Predicting the model\n",
        "\n",
        "ridge_pred=model.predict(x_test)\n",
        "score_metric(y_test,ridge_pred)"
      ],
      "metadata": {
        "id": "UCxRqO0c_rrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance\n",
        "\n",
        "feature_importance(model)"
      ],
      "metadata": {
        "id": "HmJ702iUzg4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hyperparameter tunning  on Gradient Boosting Regressor"
      ],
      "metadata": {
        "id": "qeh5gZtRwP6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Gradient Boosting Regressor from sklearn.ensemble\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "#Parameter for gradient boosting Regressor\n",
        "\n",
        "param= {'n_thread':[4],\n",
        "           'n_estimators':[1000],  #600,400],\n",
        "           'learning_rate':[0.01],  #,0.03,0.1],\n",
        "           'min_child_weight':[2],   #4,8],\n",
        "           'max_depth':[4],   #15,20],\n",
        "           'subsample':[0.5],    #0.5,1],\n",
        "           'eval_metric':['rmse'],\n",
        "           'colsample_bytree':[0.7]\n",
        "\n",
        "          }\n",
        "\n",
        "xg=GridSearchCV(XGBRegressor(),param_grid=param,cv=5)\n",
        "\n",
        "#Fitting the model\n",
        "try:\n",
        " xg.fit(x_train,y_train)\n",
        "except Exception as e:\n",
        " print(f\"Error:{e}\")\n",
        "\n",
        "#Exception handling\n",
        "\n",
        "#Printing Best parameter for model\n",
        "print('The best value to be found out:', xg.best_params_)\n",
        "\n",
        "#Predicting the model\n",
        "best_model=xg.best_estimator_\n",
        "xg_pred=best_model.predict(x_test)\n",
        "\n",
        "score_metric(y_test,xg_pred)"
      ],
      "metadata": {
        "id": "kUMbt15txJpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Score**"
      ],
      "metadata": {
        "id": "w-cQMo1g2DbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "#Specify the column name\n",
        "myTable=PrettyTable(['Model_Name','R^2 of test dataset'])\n",
        "\n",
        "#adding rows\n",
        "myTable.add_row(['Linear Regression','83%'])\n",
        "myTable.add_row(['Linear Regression with GridSearchCV','78%'])\n",
        "myTable.add_row(['Random Forest','77%'])\n",
        "myTable.add_row(['Lasso','83%'])\n",
        "myTable.add_row(['Ridge','67%'])\n",
        "myTable.add_row(['Ridge with GridSearchCV','67%'])\n",
        "myTable.add_row(['Gradient Boosting with GridSearchCV','77%'])\n",
        "\n",
        "print(myTable)"
      ],
      "metadata": {
        "id": "M8M4Gb0Z2Ofy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The rented bike count is high on Functioning_day.\n",
        "\n",
        "- The rented bike count is low on Holiday compare to working day.\n",
        "\n",
        "- The Rented bike count is high during summer and winter.\n",
        "\n",
        "- Linear Regression,Linear Regression with GridSearchCV,Random Forest,Lasso, Gradient Boosting with GridSearchCV gives highest R2 score for models.\n",
        "\n",
        "- Important Features which affect the most are winter and summer season,functioning_day,Temprature,Holiday.\n",
        "\n",
        "- Feature Importance value  for all the models are different.\n",
        "\n",
        "- We can deploy Random Forest,Lasso, Linear regression,Ridge with RandomizedSearchCV.\n",
        "\n",
        "- Therefore,Having a quality knowledge and keeping peace with the ever Ml field would surely help one to stay a step ahead in future."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}